from django.conf import settings
import json
import feedparser
from langchain_core.prompts import ChatPromptTemplate
from .ai_output_schema import blog_schema_v2
from .models import UserMessage, ModelMessage
from admin_panal.models import BlogPost, Tags, BlogUrl
from django.db import transaction


"""
This module contains the logic for generating blog posts based on an RSS feed.

The module works by:

1. Fetching an RSS feed from a randomly selected URL from the `BlogUrl` table.
2. Converting the RSS feed into a structured format for the Language Chain AI model.
3. Passing the structured data to the Language Chain AI model, which generates a blog post.
4. Saving the generated blog post to the `BlogPost` table, along with any new tags
   that were generated by the AI model.

The `fetch_feed` function fetches an RSS feed from a randomly selected URL from the
`BlogUrl` table. It returns the feed, as well as a `UserMessage` object that represents
the user's request for the feed.

The `ask_llm` function takes the feed and a `UserMessage` object, and asks the Language
Chain AI model to generate a blog post based on the feed. It returns a structured
representation of the blog post, including the title, summary, sections, external
links, and tags.

The `save_blog_posts` function takes a list of structured blog posts and saves them
to the `BlogPost` table. It also saves any new tags that were generated by the AI
model to the `Tags` table.

The module uses the `langchain_google_genai` library to interact with the Language
Chain AI model. The AI model is configured using the `settings.AI_MODEL` variable.

The module also uses the `django.db` library to interact with the database. The
`BlogUrl` and `BlogPost` models are defined in the `admin_panal` app, and the
`UserMessage` and `ModelMessage` models are defined in the `models` module of this
app.

The module uses the `transaction` library to ensure that all database operations are
atomic. If any of the operations fail, the entire transaction is rolled back.

The module uses the `itertools` library to chain together multiple iterables.

The module uses the `uuid` library to generate unique IDs for each blog post.
"""


def fetch_feed():
    """
    Fetch an RSS feed from a randomly selected URL from the `BlogUrl` table.

    Returns:
        tuple: A tuple containing the feed and a `UserMessage` object that represents
            the user's request for the feed.
    """
    url_obj = BlogUrl.objects.order_by("?").first()
    if not url_obj:
        return None
    url = url_obj.url
    feed = feedparser.parse(url)
    new_entries = []
    old_entries = set(BlogPost.objects.all().values_list("post_id", flat=True))
    for entry in feed.entries:
        raw_id = raw_id = entry.get("post-id") or entry.get("id", "")
        post_id = raw_id.split("/")[-1].split("=")[-1] if raw_id else None
        if not post_id or post_id in old_entries:
            continue
        new_entries.append(entry)
        if len(new_entries) == 5:
            break
    feed_dict = {
        "feed": feed.feed,
        "entries": new_entries if new_entries else feed.entries[:5],
    }
    user_message = UserMessage.objects.create(
        url=url,
        raw_data=json.dumps(feed_dict),
        model_used=settings.AI_MODEL
    )
    return feed_dict, user_message


def ask_llm(feed, user_message) -> dict:
    """
    Ask the Language Chain AI model to generate a blog post based on the feed.

    Args:
        feed: The RSS feed to generate a blog post for.
        user_message: The `UserMessage` object that represents the user's request for
            the feed.
        llm: The Language Chain AI model to use.

    Returns:
        dict: A structured representation of the blog post, including the title,
            summary, sections, external links, and tags.
    """
    try:
        llm = settings.LLM

        prompt_template = ChatPromptTemplate.from_messages(
            [
                ("system", "You are an expert content writer and blog generator."),
                ("human",
                 """
                Analyze the provided RSS feed data and the links associated with each topic. For each topic, generate a professional-quality blog post by researching additional context using the provided external links.

                Return each blog post as a **well-formatted markdown document** that includes:

                - unique **id** for the blog post.
                - A compelling **title** (formatted with `#` in markdown).
                - A concise and informative **summary** paragraph.
                - Multiple **sections**, each with:
                - A markdown subheading (`##` or `###`).
                - 3â€“4 paragraphs of detailed, engaging content with a minimum of 5000 words.
                - Any relevant bullet points, inline formatting, or blockquotes.
                - A list of **external links** used, formatted as markdown: `[Link Title](https://example.com)`.
                - A list of **relevant tags** at the end (formatted like a tag list).

                Format the entire content strictly in **markdown**, using appropriate syntax for:
                - Headings
                - Paragraphs
                - Lists
                - Emphasis (e.g., `**bold**`, `*italic*`)
                - External links

                Ensure the tone is professional and easy to read, and that the blog post delivers value to readers. The content should read like it belongs on a high-quality tech or business blog.
                """
                 ),
                ("human", "RSSFeed: {feed}."),
            ]
        )

        structured_llm = llm.with_structured_output(blog_schema_v2)
        chain = prompt_template | structured_llm
        response = chain.invoke({"feed": str(feed)})
    except Exception as e:
        print(f"Model Error: {e}")
        response = None
    ModelMessage.objects.create(
        parent=user_message,
        content=json.dumps(response),
        model_used=settings.AI_MODEL
    )
    return response


def save_blog_posts(data: str | dict):
    """
    Save the generated blog posts to the `BlogPost` table, along with any new tags
    that were generated by the AI model.

    Args:
        data: A list of structured blog posts to save.
    """
    if data is None:
        return
    elif isinstance(data, str):
        data = json.loads(data)
    try:
        with transaction.atomic():
            for post in data['feeds']:
                # Normalize tags to lowercase and replace spaces with dashes
                post_tags = [tag.lower().replace(" ", "-") for tag in post.pop("tags", [])]
                main_content, tags_in_content = post['content'].split("**Tags:**")
                post['content'] = main_content
                post_tags.extend(tags_in_content.lower().strip().split(", "))
                new_post = BlogPost.objects.create(**post)
                # Associate tags with the post
                for tag in post_tags:
                    tag, _ = Tags.objects.get_or_create(name=tag.replace(" ", "-"))
                    new_post.tags.add(tag)
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON: {e}")
    except Exception as e:
        print(f"Error saving blog posts: {e}")